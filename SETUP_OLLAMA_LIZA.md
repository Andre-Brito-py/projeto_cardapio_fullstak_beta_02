# ü§ñ Setup da Assistente Liza com Ollama

## Pr√©-requisitos

### 1. Instalar o Ollama

**Windows:**
```bash
# Baixar e instalar do site oficial
# https://ollama.ai/download
```

**Linux/Mac:**
```bash
curl -fsSL https://ollama.ai/install.sh | sh
```

### 2. Baixar o Modelo

```bash
# Modelo recomendado (3B par√¢metros - r√°pido e eficiente)
ollama pull llama3.2:3b

# Alternativas:
# ollama pull llama3.2:1b  # Mais r√°pido, menos preciso
# ollama pull llama3.2:7b  # Mais preciso, mais lento
```

### 3. Iniciar o Ollama

```bash
# Iniciar o servidor Ollama
ollama serve

# O servidor rodar√° em http://localhost:11434
```

## Configura√ß√£o da Liza

### 1. Verificar Conex√£o

A Liza verificar√° automaticamente se o Ollama est√° rodando. Se n√£o estiver, voc√™ ver√° a mensagem:
```
"Ollama n√£o est√° dispon√≠vel. Certifique-se de que est√° rodando em localhost:11434"
```

### 2. Comandos Dispon√≠veis

#### üìã **Gerenciamento do Card√°pio**
- `consultar card√°pio` - Lista todos os produtos
- `disponibilizar [nome do item]` - Marca item como dispon√≠vel
- `indisponibilizar [nome do item]` - Marca item como indispon√≠vel
- `alterar pre√ßo [nome do item] [valor]` - Altera pre√ßo do produto

#### üì¶ **Consulta de Pedidos**
- `pedidos em andamento` - Lista pedidos ativos
- `todos os pedidos` - Lista todos os pedidos

#### üìä **Relat√≥rios**
- `relat√≥rio do dia` - Resumo completo do dia
- `resumo de hoje` - Estat√≠sticas atuais

#### ‚ùì **Ajuda**
- `ajuda` - Lista todos os comandos dispon√≠veis

### 3. Exemplos de Uso

```
# Consultar card√°pio
Usu√°rio: "consultar card√°pio"
Liza: "üìã Card√°pio (15 itens): ..."

# Alterar disponibilidade
Usu√°rio: "indisponibilizar Pizza Margherita"
Liza: "‚úÖ Pizza Margherita foi indisponibilizada com sucesso!"

# Alterar pre√ßo
Usu√°rio: "alterar pre√ßo Hamb√∫rguer Cl√°ssico 25.90"
Liza: "‚úÖ Pre√ßo de Hamb√∫rguer Cl√°ssico alterado para R$ 25.90!"

# Consultar pedidos
Usu√°rio: "pedidos em andamento"
Liza: "üì¶ Pedidos em Andamento (3): ..."

# Gerar relat√≥rio
Usu√°rio: "relat√≥rio do dia"
Liza: "üìä Relat√≥rio do Dia - 15/01/2024: ..."
```

## Arquitetura da Solu√ß√£o

### Fluxo de Comunica√ß√£o

```
Admin Interface ‚Üí LizaService ‚Üí OllamaService + BackendService
                                      ‚Üì
                              Ollama Local (llama3.2:3b)
                                      ‚Üì
                              Backend APIs (MongoDB)
```

### Servi√ßos Implementados

1. **OllamaService** (`/admin/src/services/ollamaService.js`)
   - Comunica√ß√£o direta com Ollama
   - Processamento de linguagem natural
   - Constru√ß√£o de prompts contextuais

2. **BackendService** (`/admin/src/services/backendService.js`)
   - Integra√ß√£o com APIs do backend
   - Opera√ß√µes CRUD no card√°pio
   - Consultas de pedidos e relat√≥rios

3. **LizaService** (`/admin/src/services/lizaService.js`)
   - Orquestra√ß√£o entre Ollama e Backend
   - Reconhecimento de comandos
   - Formata√ß√£o de respostas

## Troubleshooting

### Problema: "Ollama n√£o est√° dispon√≠vel"
**Solu√ß√£o:**
```bash
# Verificar se o Ollama est√° rodando
curl http://localhost:11434/api/tags

# Se n√£o estiver, iniciar:
ollama serve
```

### Problema: "Modelo n√£o encontrado"
**Solu√ß√£o:**
```bash
# Baixar o modelo
ollama pull llama3.2:3b

# Verificar modelos instalados
ollama list
```

### Problema: Respostas lentas
**Solu√ß√µes:**
1. Usar modelo menor: `ollama pull llama3.2:1b`
2. Aumentar RAM dispon√≠vel
3. Usar GPU se dispon√≠vel

### Problema: Erro de autentica√ß√£o no backend
**Solu√ß√£o:**
- Verificar se o token est√° v√°lido no localStorage
- Fazer login novamente no admin

## Performance

### Requisitos M√≠nimos
- **RAM:** 8GB (recomendado 16GB)
- **CPU:** 4 cores
- **Armazenamento:** 5GB livres

### Otimiza√ß√µes
- Modelo `llama3.2:1b` para m√°quinas mais lentas
- Modelo `llama3.2:3b` para uso geral (recomendado)
- Modelo `llama3.2:7b` para m√°xima precis√£o

## Seguran√ßa

‚úÖ **Vantagens da Solu√ß√£o Local:**
- Dados n√£o saem do servidor
- Sem depend√™ncia de APIs externas
- Controle total sobre o processamento
- Sem custos por uso
- Funciona offline

## Monitoramento

### Logs do Ollama
```bash
# Ver logs do Ollama
ollama logs
```

### Logs da Liza
- Console do navegador (F12)
- Network tab para requisi√ß√µes
- Mensagens de erro no chat

## Pr√≥ximos Passos

1. **Testar todos os comandos** listados acima
2. **Configurar modelo preferido** baseado na performance
3. **Treinar equipe** nos comandos dispon√≠veis
4. **Monitorar performance** e ajustar conforme necess√°rio

---

**üéâ A Liza est√° pronta para uso!**

Para suporte t√©cnico, consulte os logs ou entre em contato com a equipe de desenvolvimento.